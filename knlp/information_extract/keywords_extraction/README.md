参考了letiantian的代码进行的重构。
https://github.com/letiantian/TextRank4ZH/blob/master/textrank4zh

资料：

pagerank: https://www.letiantian.me/2014-06-10-pagerank/

textrank: https://www.letiantian.me/2014-12-01-text-rank/

关键词提取的重要技术点：

将原文本拆分为句子，在每个句子中过滤掉停用词（可选），并只保留指定词性的单词（可选）。由此可以得到句子的集合和单词的集合。 --- **可以考虑把识别出来的实体也作为标签留下来**

针对以下两个进行分别处理：
title

passage

句子的集合和单词的集合。

每个单词作为pagerank中的一个节点。设定窗口大小为k，假设一个句子依次由下面的单词组成：

w1,w2,w3,w4,w5,…,wn
[w1,w2,…,wk]、[w2,w3,…,wk+1]、[w3,w4,…,wk+2]等都是一个窗口。在一个窗口中的任两个单词对应的节点之间存在一个无向无权的边。

基于上面构成图，可以计算出每个单词节点的重要性。最重要的若干单词可以作为关键词。

在一个窗口内进行权重计算。不断更新单词的权重。

**这里明显是有文章可以做的**

参照“使用TextRank提取关键词”提取出若干关键词。若原文本中存在若干个关键词相邻的情况，那么这些关键词可以构成一个关键短语。

摘要这里，是计算句子之间的相似度作为权重，这里有点扯淡，应该直接使用句子中包含的单词的权重，来sum平均作为总权重吧。

## 引入关键词表label

1. 对文件名的切词使用搜索模式，或者考虑直接进行全排列，然后利用label词表进行遍历，存在即返回
jieba.cut_for_search
2. 对关键短语使用相同的方式进行处理。
